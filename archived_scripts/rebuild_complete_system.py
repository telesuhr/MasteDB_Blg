"""
å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ å†æ§‹ç¯‰: 1ã‹ã‚‰Bloomberg APIã§ãƒ‡ãƒ¼ã‚¿å–å¾—
å…¨ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ â†’ æ—¥åˆ¥ãƒãƒƒãƒ”ãƒ³ã‚°å–å¾— â†’ ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾— â†’ å®Ÿå¥‘ç´„IDè¨­å®š
"""
import sys
import os
from datetime import datetime, date, timedelta
import pandas as pd

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã¨srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.abspath(__file__))
src_dir = os.path.join(project_root, 'src')
sys.path.insert(0, project_root)
sys.path.insert(0, src_dir)

from bloomberg_api import BloombergDataFetcher
from database import DatabaseManager
from config.logging_config import logger

class CompleteSystemRebuilder:
    """å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ å†æ§‹ç¯‰ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.bloomberg = BloombergDataFetcher()
        self.db_manager = DatabaseManager()
        
    def rebuild_complete_system(self, days_back=5):
        """å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ å†æ§‹ç¯‰"""
        logger.info("=== å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ å†æ§‹ç¯‰é–‹å§‹ ===")
        
        try:
            # Bloomberg APIæ¥ç¶š
            if not self.bloomberg.connect():
                raise ConnectionError("Bloomberg APIæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")
                
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
            self.db_manager.connect()
            
            # Step 1: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self._cleanup_existing_data()
            
            # Step 2: å¯¾è±¡æœŸé–“ã®æ±ºå®š
            end_date = datetime.now().date()
            start_date = end_date - timedelta(days=days_back)
            business_dates = self._get_business_dates(start_date, end_date)
            
            logger.info(f"å¯¾è±¡æœŸé–“: {start_date} - {end_date}")
            logger.info(f"å–¶æ¥­æ—¥: {business_dates}")
            
            # Step 3: å„å–¶æ¥­æ—¥ã®ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿å–å¾—
            for business_date in business_dates:
                self._build_daily_mapping(business_date)
                
            # Step 4: å„å–¶æ¥­æ—¥ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—
            for business_date in business_dates:
                self._fetch_daily_price_data(business_date)
                
            # Step 5: çµ±åˆç¢ºèª
            self._verify_integration()
            
            logger.info("=== å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ å†æ§‹ç¯‰å®Œäº† ===")
            return True
            
        except Exception as e:
            logger.error(f"ã‚·ã‚¹ãƒ†ãƒ å†æ§‹ç¯‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            return False
            
        finally:
            self.bloomberg.disconnect()
            self.db_manager.disconnect()
            
    def _cleanup_existing_data(self):
        """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        logger.info("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹...")
        
        try:
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                
                # å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã®ãŸã‚ã€é€†é †ã§å‰Šé™¤
                cleanup_queries = [
                    "DELETE FROM T_CommodityPrice_V2",
                    "DELETE FROM T_GenericContractMapping", 
                    "DELETE FROM M_ActualContract"
                ]
                
                for query in cleanup_queries:
                    cursor.execute(query)
                    deleted_count = cursor.rowcount
                    table_name = query.split()[-1]
                    logger.info(f"{table_name}: {deleted_count}ä»¶å‰Šé™¤")
                
                conn.commit()
                logger.info("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
                
        except Exception as e:
            logger.error(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            
    def _get_business_dates(self, start_date, end_date):
        """å–¶æ¥­æ—¥ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ"""
        business_dates = []
        current_date = start_date
        
        while current_date <= end_date:
            # åœŸæ—¥ã‚’é™¤å¤–ï¼ˆç¥æ—¥ã¯ç°¡æ˜“çš„ã«é™¤å¤–ã—ãªã„ï¼‰
            if current_date.weekday() < 5:  # 0=æœˆæ›œ, 6=æ—¥æ›œ
                business_dates.append(current_date)
            current_date += timedelta(days=1)
            
        return business_dates
        
    def _build_daily_mapping(self, business_date):
        """ç‰¹å®šæ—¥ã®ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰"""
        logger.info(f"ãƒãƒƒãƒ”ãƒ³ã‚°æ§‹ç¯‰: {business_date}")
        
        try:
            # ã‚¸ã‚§ãƒãƒªãƒƒã‚¯å…ˆç‰©ãƒªã‚¹ãƒˆ
            test_tickers = ['LP1 Comdty', 'LP2 Comdty', 'LP3 Comdty']
            
            # Bloomberg APIã‹ã‚‰ç¾åœ¨ã®å®Ÿå¥‘ç´„ã‚’å–å¾—
            mapping_fields = [
                'FUT_CUR_GEN_TICKER',     # ç¾åœ¨ã®å®Ÿå¥‘ç´„
                'LAST_TRADEABLE_DT',      # æœ€çµ‚å–å¼•æ—¥
                'FUT_DLV_DT_LAST',        # æœ€çµ‚å¼•æ¸¡æ—¥
                'FUT_CONTRACT_DT',        # å¥‘ç´„æœˆ
                'FUT_CONT_SIZE',          # å¥‘ç´„ã‚µã‚¤ã‚º
                'FUT_TICK_SIZE'           # ãƒ†ã‚£ãƒƒã‚¯ã‚µã‚¤ã‚º
            ]
            
            # ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆç¾åœ¨æ™‚ç‚¹ï¼‰
            ref_data = self.bloomberg.get_reference_data(test_tickers, mapping_fields)
            
            if ref_data.empty:
                logger.warning(f"ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {business_date}")
                return
                
            # ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨æ ¼ç´
            self._process_daily_mapping(business_date, ref_data)
            
        except Exception as e:
            logger.error(f"ãƒãƒƒãƒ”ãƒ³ã‚°æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼ ({business_date}): {e}")
            
    def _process_daily_mapping(self, business_date, ref_data):
        """æ—¥åˆ¥ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
        try:
            # ã‚¸ã‚§ãƒãƒªãƒƒã‚¯å…ˆç‰©æƒ…å ±ã‚’å–å¾—
            with self.db_manager.get_connection() as conn:
                query = """
                    SELECT GenericID, GenericTicker, MetalID, ExchangeCode
                    FROM M_GenericFutures 
                    WHERE GenericTicker IN ('LP1 Comdty', 'LP2 Comdty', 'LP3 Comdty')
                    ORDER BY GenericNumber
                """
                generic_info = pd.read_sql(query, conn)
                
            for _, row in ref_data.iterrows():
                security = row['security']
                current_generic = row.get('FUT_CUR_GEN_TICKER')
                
                if pd.isna(current_generic):
                    logger.warning(f"å®Ÿå¥‘ç´„å–å¾—å¤±æ•—: {security}")
                    continue
                    
                logger.info(f"{business_date}: {security} -> {current_generic}")
                
                # ã‚¸ã‚§ãƒãƒªãƒƒã‚¯æƒ…å ±ã‚’å–å¾—
                generic_row = generic_info[generic_info['GenericTicker'] == security]
                if len(generic_row) == 0:
                    continue
                    
                generic_row = generic_row.iloc[0]
                
                # å®Ÿå¥‘ç´„ã‚’M_ActualContractã«æ ¼ç´
                actual_contract_id = self._create_actual_contract(current_generic, generic_row, row)
                
                if actual_contract_id:
                    # ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
                    self._create_mapping(
                        business_date, 
                        int(generic_row['GenericID']), 
                        actual_contract_id, 
                        row
                    )
                    
        except Exception as e:
            logger.error(f"ãƒãƒƒãƒ”ãƒ³ã‚°å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({business_date}): {e}")
            
    def _create_actual_contract(self, contract_ticker, generic_info, row):
        """å®Ÿå¥‘ç´„ã‚’ä½œæˆã¾ãŸã¯å–å¾—"""
        try:
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                
                # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
                cursor.execute(
                    "SELECT ActualContractID FROM M_ActualContract WHERE ContractTicker = ?",
                    (contract_ticker,)
                )
                existing = cursor.fetchone()
                
                if existing:
                    return existing[0]
                    
                # å¥‘ç´„æœˆã®è§£æ
                contract_date = row.get('FUT_CONTRACT_DT')
                contract_month = None
                contract_year = None
                contract_month_code = None
                
                if not pd.isna(contract_date):
                    try:
                        if isinstance(contract_date, str):
                            contract_dt = pd.to_datetime(contract_date)
                        else:
                            contract_dt = contract_date
                        contract_month = contract_dt.replace(day=1).date()
                        contract_year = contract_dt.year
                        
                        # æœˆã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
                        month_codes = ['F', 'G', 'H', 'J', 'K', 'M', 'N', 'Q', 'U', 'V', 'X', 'Z']
                        contract_month_code = month_codes[contract_dt.month - 1]
                        
                    except Exception as e:
                        logger.warning(f"å¥‘ç´„æœˆè§£æå¤±æ•—: {contract_date}, ã‚¨ãƒ©ãƒ¼: {e}")
                
                # æ–°è¦ä½œæˆ
                cursor.execute("""
                    INSERT INTO M_ActualContract (
                        ContractTicker, MetalID, ExchangeCode, ContractMonth, 
                        ContractYear, ContractMonthCode, LastTradeableDate, 
                        DeliveryDate, ContractSize, TickSize
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    contract_ticker,
                    int(generic_info['MetalID']),
                    generic_info['ExchangeCode'],
                    contract_month,
                    contract_year,
                    contract_month_code,
                    row.get('LAST_TRADEABLE_DT'),
                    row.get('FUT_DLV_DT_LAST'),
                    float(row.get('FUT_CONT_SIZE')) if not pd.isna(row.get('FUT_CONT_SIZE')) else None,
                    float(row.get('FUT_TICK_SIZE')) if not pd.isna(row.get('FUT_TICK_SIZE')) else None
                ))
                
                cursor.execute("SELECT @@IDENTITY")
                actual_contract_id = cursor.fetchone()[0]
                conn.commit()
                
                logger.info(f"å®Ÿå¥‘ç´„ä½œæˆ: {contract_ticker} (ID: {actual_contract_id})")
                return actual_contract_id
                
        except Exception as e:
            logger.error(f"å®Ÿå¥‘ç´„ä½œæˆã‚¨ãƒ©ãƒ¼ ({contract_ticker}): {e}")
            return None
            
    def _create_mapping(self, business_date, generic_id, actual_contract_id, row):
        """ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ"""
        try:
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                
                # æ®‹å­˜æ—¥æ•°è¨ˆç®—
                days_to_expiry = None
                last_tradeable = row.get('LAST_TRADEABLE_DT')
                if not pd.isna(last_tradeable):
                    try:
                        if isinstance(last_tradeable, str):
                            last_tradeable_dt = pd.to_datetime(last_tradeable).date()
                        else:
                            last_tradeable_dt = last_tradeable
                        days_to_expiry = (last_tradeable_dt - business_date).days
                    except Exception as e:
                        logger.warning(f"æ®‹å­˜æ—¥æ•°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                
                # ãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆ
                cursor.execute("""
                    INSERT INTO T_GenericContractMapping (
                        TradeDate, GenericID, ActualContractID, DaysToExpiry
                    ) VALUES (?, ?, ?, ?)
                """, (business_date, generic_id, actual_contract_id, days_to_expiry))
                
                conn.commit()
                logger.info(f"ãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆ: {business_date} - ã‚¸ã‚§ãƒãƒªãƒƒã‚¯ID {generic_id} -> å®Ÿå¥‘ç´„ID {actual_contract_id}")
                
        except Exception as e:
            logger.error(f"ãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            
    def _fetch_daily_price_data(self, business_date):
        """ç‰¹å®šæ—¥ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        logger.info(f"ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—: {business_date}")
        
        try:
            test_tickers = ['LP1 Comdty', 'LP2 Comdty', 'LP3 Comdty']
            price_fields = [
                'PX_LAST', 'PX_OPEN', 'PX_HIGH', 'PX_LOW', 'PX_VOLUME', 'OPEN_INT'
            ]
            
            # å˜æ—¥ã®ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—
            date_str = business_date.strftime('%Y%m%d')
            price_data = self.bloomberg.get_historical_data(
                test_tickers, price_fields, date_str, date_str
            )
            
            if price_data.empty:
                logger.warning(f"ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {business_date}")
                return
                
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨æ ¼ç´
            self._process_price_data(price_data, business_date)
            
        except Exception as e:
            logger.error(f"ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ ({business_date}): {e}")
            
    def _process_price_data(self, price_data, business_date):
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨æ ¼ç´"""
        try:
            # ã‚¸ã‚§ãƒãƒªãƒƒã‚¯ãƒ»ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ã‚’å–å¾—
            with self.db_manager.get_connection() as conn:
                query = """
                    SELECT g.GenericID, g.GenericTicker, g.MetalID, m.ActualContractID
                    FROM M_GenericFutures g
                    JOIN T_GenericContractMapping m ON m.GenericID = g.GenericID
                    WHERE m.TradeDate = ?
                        AND g.GenericTicker IN ('LP1 Comdty', 'LP2 Comdty', 'LP3 Comdty')
                """
                mapping_info = pd.read_sql(query, conn, params=[business_date])
                
            mapping_dict = {}
            for _, row in mapping_info.iterrows():
                mapping_dict[row['GenericTicker']] = {
                    'GenericID': row['GenericID'],
                    'MetalID': row['MetalID'],
                    'ActualContractID': row['ActualContractID']
                }
                
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿æ ¼ç´
            with self.db_manager.get_connection() as conn:
                cursor = conn.cursor()
                
                for _, row in price_data.iterrows():
                    security = row['security']
                    trade_date = pd.to_datetime(row['date']).date()
                    
                    if security not in mapping_dict:
                        continue
                        
                    mapping = mapping_dict[security]
                    
                    # ä¾¡æ ¼ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆ
                    cursor.execute("""
                        INSERT INTO T_CommodityPrice_V2 (
                            TradeDate, MetalID, DataType, GenericID, ActualContractID,
                            SettlementPrice, OpenPrice, HighPrice, LowPrice, LastPrice,
                            Volume, OpenInterest
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        trade_date,
                        int(mapping['MetalID']),
                        'Generic',
                        int(mapping['GenericID']),
                        int(mapping['ActualContractID']),
                        self._safe_float(row.get('PX_LAST')),
                        self._safe_float(row.get('PX_OPEN')),
                        self._safe_float(row.get('PX_HIGH')),
                        self._safe_float(row.get('PX_LOW')),
                        self._safe_float(row.get('PX_LAST')),
                        self._safe_int(row.get('PX_VOLUME')),
                        self._safe_int(row.get('OPEN_INT'))
                    ))
                    
                    logger.info(f"ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿æ ¼ç´: {security} - {trade_date}")
                
                conn.commit()
                
        except Exception as e:
            logger.error(f"ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({business_date}): {e}")
            
    def _safe_float(self, value):
        """å®‰å…¨ãªfloatå¤‰æ›"""
        if value is None or pd.isna(value):
            return None
        try:
            return float(value)
        except (ValueError, TypeError):
            return None
            
    def _safe_int(self, value):
        """å®‰å…¨ãªintå¤‰æ›"""
        if value is None or pd.isna(value):
            return None
        try:
            return int(float(value))
        except (ValueError, TypeError):
            return None
            
    def _verify_integration(self):
        """çµ±åˆç¢ºèª"""
        logger.info("çµ±åˆç¢ºèªé–‹å§‹...")
        
        try:
            with self.db_manager.get_connection() as conn:
                # çµ±åˆã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆ
                integration_query = """
                    SELECT 
                        p.TradeDate,
                        g.GenericTicker,
                        a.ContractTicker,
                        m.DaysToExpiry,
                        p.SettlementPrice,
                        p.Volume
                    FROM T_CommodityPrice_V2 p
                    JOIN M_GenericFutures g ON p.GenericID = g.GenericID
                    JOIN M_ActualContract a ON p.ActualContractID = a.ActualContractID
                    JOIN T_GenericContractMapping m ON m.GenericID = g.GenericID 
                        AND m.TradeDate = p.TradeDate
                    WHERE p.DataType = 'Generic'
                    ORDER BY p.TradeDate, g.GenericNumber
                """
                
                result_df = pd.read_sql(integration_query, conn)
                
                if not result_df.empty:
                    logger.info(f"çµ±åˆç¢ºèªæˆåŠŸ: {len(result_df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ã«é€£æº")
                    print("\n=== çµ±åˆç¢ºèªçµæœ ===")
                    print(result_df.to_string(index=False))
                else:
                    logger.error("çµ±åˆç¢ºèªå¤±æ•—: ãƒ‡ãƒ¼ã‚¿ãŒé€£æºã•ã‚Œã¦ã„ã¾ã›ã‚“")
                    
        except Exception as e:
            logger.error(f"çµ±åˆç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ å†æ§‹ç¯‰é–‹å§‹")
    
    rebuilder = CompleteSystemRebuilder()
    success = rebuilder.rebuild_complete_system(days_back=5)
    
    if success:
        print("\n" + "ğŸ‰ " * 20)
        print("ğŸ‰ å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ å†æ§‹ç¯‰æˆåŠŸï¼")
        print("ğŸ‰ ã‚¸ã‚§ãƒãƒªãƒƒã‚¯ãƒ»å®Ÿå¥‘ç´„ãƒ»ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒå®Œå…¨ã«é€£æºã•ã‚Œã¾ã—ãŸï¼")
        print("ğŸ‰ " * 20)
    else:
        logger.error("å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ å†æ§‹ç¯‰å¤±æ•—")
        
    return success

if __name__ == "__main__":
    main()